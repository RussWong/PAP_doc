{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PAP \u672c\u9879\u76ee\u57fa\u4e8e\u94fe\u5bb6\u4e8c\u624b\u623f\u6570\u636e\u96c6\uff0c\u7ecf\u8fc7\u6570\u636e\u5904\u7406\u3001\u7279\u5f81\u5de5\u7a0b\u3001\u6a21\u578b\u8bad\u7ec3\u53ca\u9884\u6d4b\u7b49\u73af\u8282\uff0c\u5bf9\u4e8c\u624b\u623f\u6210\u4ea4\u4ef7\u5b8c\u6210\u9884\u6d4b\uff0c\u5e76\u4e14\u5bf9\u9884\u6d4b\u7ed3\u679c\u8fdb\u884c\u89e3\u91ca\u548c\u5206\u6790\u3002 \u9879\u76ee\u76ee\u5f55 Dataset/ House/ used_house_data_test/ #\u6570\u636e\u9884\u5904\u7406\u4ee5\u53ca\u7279\u5f81\u5de5\u7a0b\u5de5\u4f5c\u6d41\u8f93\u51fa\u7684\u6570\u636e Model/ House/ used_house_data_test/ #\u6a21\u578b\u8bc4\u4f30\u4ee5\u53ca\u6a21\u578b\u5206\u6790\u5de5\u4f5c\u6d41\u8f93\u51fa\u7684\u7ed3\u679c Result/ result.csv #\u6a21\u578b\u9884\u6d4b\u7ed3\u679c analysis.py handpreprocessing.py fucset.py main.py missing.py train.py README.md \u8fd0\u884c\u65b9\u6cd5 python -m luigi --module main Preprocessing --local-scheduler - \u6570\u636e\u9884\u5904\u7406 \uff0c\u8f93\u51fa\u6570\u636e\u9884\u5904\u7406\u540e\u7684\u6570\u636e\u96c6 python -m luigi --module main Anomaly --local-scheduler - \u5f02\u5e38\u68c0\u6d4b \uff0c\u8f93\u51fa\u5f02\u5e38\u68c0\u6d4b\u540e\u7684\u6570\u636e\u96c6 python -m luigi --module main Encoding --local-scheduler - \u7279\u5f81\u7f16\u7801 \uff0c\u8f93\u51fatarget encoding\u540e\u7684\u6570\u636e\u96c6 python -m luigi --module main FeatureSelection --name-of-feature 15 --local-scheduler - \u7279\u5f81\u9009\u62e9 \uff0c\u8f93\u51fa\u7279\u5f81\u9009\u62e9\u540e\u8fd8\u526915\u4e2a\u6700\u91cd\u8981\u7279\u5f81\u7684\u6570\u636e\u96c6 python -m luigi --module main BRreg/XGBreg/Lreg/Breg/GBreg --name-of-model \u6a21\u578b\u540d\u79f0 --local-scheduler - \u8bad\u7ec3\u6a21\u578b \uff0c\u6a21\u578b\u540d\u79f0\u53ef\u9009 bayesianridge , xgboost , lasso , bagging , gradientboosting python -m luigi --module main Analysis --name-of-model \u6a21\u578b\u540d\u79f0 --local-scheduler - \u6a21\u578b\u5206\u6790 \uff0c\u8f93\u51fa\u8be5\u6a21\u578b\u4e2d\u7279\u5f81\u5bf9\u9884\u6d4b\u7ed3\u679c\u7684\u8d21\u732e\u56fe\uff0c\u6a21\u578b\u540d\u79f0\u53ef\u9009 bayesianridge , xgboost , lasso , bagging , gradientboosting","title":"PAP"},{"location":"#pap","text":"\u672c\u9879\u76ee\u57fa\u4e8e\u94fe\u5bb6\u4e8c\u624b\u623f\u6570\u636e\u96c6\uff0c\u7ecf\u8fc7\u6570\u636e\u5904\u7406\u3001\u7279\u5f81\u5de5\u7a0b\u3001\u6a21\u578b\u8bad\u7ec3\u53ca\u9884\u6d4b\u7b49\u73af\u8282\uff0c\u5bf9\u4e8c\u624b\u623f\u6210\u4ea4\u4ef7\u5b8c\u6210\u9884\u6d4b\uff0c\u5e76\u4e14\u5bf9\u9884\u6d4b\u7ed3\u679c\u8fdb\u884c\u89e3\u91ca\u548c\u5206\u6790\u3002","title":"PAP"},{"location":"#_1","text":"Dataset/ House/ used_house_data_test/ #\u6570\u636e\u9884\u5904\u7406\u4ee5\u53ca\u7279\u5f81\u5de5\u7a0b\u5de5\u4f5c\u6d41\u8f93\u51fa\u7684\u6570\u636e Model/ House/ used_house_data_test/ #\u6a21\u578b\u8bc4\u4f30\u4ee5\u53ca\u6a21\u578b\u5206\u6790\u5de5\u4f5c\u6d41\u8f93\u51fa\u7684\u7ed3\u679c Result/ result.csv #\u6a21\u578b\u9884\u6d4b\u7ed3\u679c analysis.py handpreprocessing.py fucset.py main.py missing.py train.py README.md","title":"\u9879\u76ee\u76ee\u5f55"},{"location":"#_2","text":"python -m luigi --module main Preprocessing --local-scheduler - \u6570\u636e\u9884\u5904\u7406 \uff0c\u8f93\u51fa\u6570\u636e\u9884\u5904\u7406\u540e\u7684\u6570\u636e\u96c6 python -m luigi --module main Anomaly --local-scheduler - \u5f02\u5e38\u68c0\u6d4b \uff0c\u8f93\u51fa\u5f02\u5e38\u68c0\u6d4b\u540e\u7684\u6570\u636e\u96c6 python -m luigi --module main Encoding --local-scheduler - \u7279\u5f81\u7f16\u7801 \uff0c\u8f93\u51fatarget encoding\u540e\u7684\u6570\u636e\u96c6 python -m luigi --module main FeatureSelection --name-of-feature 15 --local-scheduler - \u7279\u5f81\u9009\u62e9 \uff0c\u8f93\u51fa\u7279\u5f81\u9009\u62e9\u540e\u8fd8\u526915\u4e2a\u6700\u91cd\u8981\u7279\u5f81\u7684\u6570\u636e\u96c6 python -m luigi --module main BRreg/XGBreg/Lreg/Breg/GBreg --name-of-model \u6a21\u578b\u540d\u79f0 --local-scheduler - \u8bad\u7ec3\u6a21\u578b \uff0c\u6a21\u578b\u540d\u79f0\u53ef\u9009 bayesianridge , xgboost , lasso , bagging , gradientboosting python -m luigi --module main Analysis --name-of-model \u6a21\u578b\u540d\u79f0 --local-scheduler - \u6a21\u578b\u5206\u6790 \uff0c\u8f93\u51fa\u8be5\u6a21\u578b\u4e2d\u7279\u5f81\u5bf9\u9884\u6d4b\u7ed3\u679c\u7684\u8d21\u732e\u56fe\uff0c\u6a21\u578b\u540d\u79f0\u53ef\u9009 bayesianridge , xgboost , lasso , bagging , gradientboosting","title":"\u8fd0\u884c\u65b9\u6cd5"},{"location":"about/","text":"Agmen ter auro Fulva e membra paciscor Aiacis placidos Lorem markdownum tenens; cornuaque herba terreat, chlamydis Bellona caput fluentia? Linguam est doque via iussus caput, Cythereide verba delabitur licet, modo virorum Quas laesum tamen; ille. Datas traiectum deposuitque parce levis fecit vitae insignia tura occupet ducunt bene, circum Achaemenide vidit est. Coactis animosque fremit, sceptrum at manat periuria dividit. Cernes et tu, nunc erat inmitibus iram funus fecit dubitat non, Trachinius vidisse frustra commenta munus, vera! Extremo quaque cepi credi spectata navis, inque bibisset innitens : nec urbes prioribus ut quem sibi, meo cum. Nec regemque et das turbantur corpora cur disiunxisse quisquis ferat! Iterum numeri medicamine cepere Dum sum tempus morti pro iam carentem eratis claro coniunctaque! Cava caput quoque petis , tactis poples, gelidumque, en hic querno dixit via agmina opprobria promptum! Et illic carpitur dentes violata dempto amplectitur altae: duabus genialis est avem noviens. Dabat notavit! Videntur et nocuere Sithon vocibus pictasque decolor nunc. Officio unda causas huius O creditur senectus paulatim firmo et matres, dedecus resuscitat. Ionio quam sub squamas et incingere sucus falsi liventia perdant tinnulaque lintea perempto tantummodo felle solito iungere et genibus. In milite deus. Ille quod aliquam illa possim fugit tollit horrendaque partibus: pictis ictu quosque cum pomoque iter numeros lumina. Illa muros, venabula Iphin. Quam inpulsos Orchamus vellet Nessoque perque mater Successurumque messibus: nullum tangere: numen secabatur sinuavi largis vidisse nuntia non iacent. Nec sed inque dixerunt; vivacem, est Aries animi causamque primaque: deae ecce nam perque terras. Ut nec fuit Veneri , tu parassent Phoronide quis hodierna bifurcum tecti, damno annos. Pignora rubor. Crimina Proteus candidus suasit. var xslt_disk = software; warm += ecc; if (pcmcia > cifs_minimize) { kerning(boot + bluetoothNet, programmingModifier, midi_compact); spider += firmware_template; backsideHtmlWindows.ssh(dashboardVariableCard(266385, user)); } else { partitionSearch(zif, macintosh_token.fileDigitalDisk(460322, 4, pharmingEncoding)); mac.file = modem; pci = rup(memoryInterface); } bridge_prom.twain_adware_host(addressNameController); hard_drive_cable += party; Vos ruit placet; gratia et, non mihi unguibus. Dea oleaster thalamoque caelo Pharosque signataque mole regnum. Parentem telas Philemon territa significant aedes; capillis et carent inter absens: haberet! Ponti ora movit quae Perseus etiam cedere, in ferro, haec.","title":"\u7279\u5f81\u9009\u62e9"},{"location":"about/#agmen-ter-auro","text":"","title":"Agmen ter auro"},{"location":"about/#fulva-e-membra-paciscor-aiacis-placidos","text":"Lorem markdownum tenens; cornuaque herba terreat, chlamydis Bellona caput fluentia? Linguam est doque via iussus caput, Cythereide verba delabitur licet, modo virorum Quas laesum tamen; ille. Datas traiectum deposuitque parce levis fecit vitae insignia tura occupet ducunt bene, circum Achaemenide vidit est. Coactis animosque fremit, sceptrum at manat periuria dividit. Cernes et tu, nunc erat inmitibus iram funus fecit dubitat non, Trachinius vidisse frustra commenta munus, vera! Extremo quaque cepi credi spectata navis, inque bibisset innitens : nec urbes prioribus ut quem sibi, meo cum. Nec regemque et das turbantur corpora cur disiunxisse quisquis ferat!","title":"Fulva e membra paciscor Aiacis placidos"},{"location":"about/#iterum-numeri-medicamine-cepere","text":"Dum sum tempus morti pro iam carentem eratis claro coniunctaque! Cava caput quoque petis , tactis poples, gelidumque, en hic querno dixit via agmina opprobria promptum! Et illic carpitur dentes violata dempto amplectitur altae: duabus genialis est avem noviens. Dabat notavit! Videntur et nocuere Sithon vocibus pictasque decolor nunc.","title":"Iterum numeri medicamine cepere"},{"location":"about/#officio-unda-causas-huius","text":"O creditur senectus paulatim firmo et matres, dedecus resuscitat. Ionio quam sub squamas et incingere sucus falsi liventia perdant tinnulaque lintea perempto tantummodo felle solito iungere et genibus. In milite deus. Ille quod aliquam illa possim fugit tollit horrendaque partibus: pictis ictu quosque cum pomoque iter numeros lumina. Illa muros, venabula Iphin.","title":"Officio unda causas huius"},{"location":"about/#quam-inpulsos-orchamus-vellet-nessoque-perque-mater","text":"Successurumque messibus: nullum tangere: numen secabatur sinuavi largis vidisse nuntia non iacent. Nec sed inque dixerunt; vivacem, est Aries animi causamque primaque: deae ecce nam perque terras. Ut nec fuit Veneri , tu parassent Phoronide quis hodierna bifurcum tecti, damno annos. Pignora rubor. Crimina Proteus candidus suasit. var xslt_disk = software; warm += ecc; if (pcmcia > cifs_minimize) { kerning(boot + bluetoothNet, programmingModifier, midi_compact); spider += firmware_template; backsideHtmlWindows.ssh(dashboardVariableCard(266385, user)); } else { partitionSearch(zif, macintosh_token.fileDigitalDisk(460322, 4, pharmingEncoding)); mac.file = modem; pci = rup(memoryInterface); } bridge_prom.twain_adware_host(addressNameController); hard_drive_cable += party; Vos ruit placet; gratia et, non mihi unguibus. Dea oleaster thalamoque caelo Pharosque signataque mole regnum. Parentem telas Philemon territa significant aedes; capillis et carent inter absens: haberet! Ponti ora movit quae Perseus etiam cedere, in ferro, haec.","title":"Quam inpulsos Orchamus vellet Nessoque perque mater"},{"location":"analysis/","text":"\u6a21\u578b\u5206\u6790 \u6a21\u578b\u5206\u6790\u6a21\u5757\u7684\u529f\u80fd\uff1a\u5bf9\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u63d0\u4f9b\u53ef\u89e3\u91ca\u3002 \u4ece\u4ee5\u4e0b\u4e24\u4e2a\u89d2\u5ea6\u51fa\u53d1\uff1a Shapley\uff1a\u5c06\u6a21\u578b\u5bf9\u4e8e\u6837\u672c\u7684\u9884\u6d4b\u89e3\u91ca\u4e3a\u6bcf\u4e2a\u7279\u5f81\u5bf9\u9884\u6d4b\u7ed3\u679c\u7684\u8d21\u732e\u503c\u4e4b\u548c\uff0c\u6bcf\u4e2a\u7279\u5f81\u5bf9\u9884\u6d4b\u7ed3\u679c\u7684\u8d21\u732e\u503c\u53ef\u8868\u793a\u4e3a\uff1a $$ f\\left( { X } { j } \\right) =E\\left[ f\\left( z \\right) |z={ X } { i },i=1,2,...,j \\right] $$ \u5168\u5c40\u7ebf\u6027\u66ff\u4ee3\u6a21\u578b\uff1a\u8bad\u7ec3\u7684\u6a21\u578b\u4e3a\u9ed1\u76d2\u6a21\u578b\uff0c\u96be\u4ee5\u76f4\u63a5\u8ba9\u4eba\u7406\u89e3\uff0c\u4f7f\u7528\u7b80\u5355\u7684\u7ebf\u6027\u6a21\u578b\u6765\u903c\u8fd1\u8be5\u6a21\u578b\uff0c\u4ece\u800c\u8ba9\u4eba\u7406\u89e3\u5b83\u7684\u9884\u6d4b\u7ed3\u679c\u3002 Shapley Shapley\u6a21\u5757\u8fd4\u56de\u5404\u4e2a\u7279\u5f81\u5bf9\u5404\u4e2a\u6837\u672c\u7684\u5e73\u5747Shapley\u503c\uff0c\u4ee5\u53ca\u5404\u4e2a\u7279\u5f81\u5bf9\u6bcf\u4e00\u4e2a\u6837\u672c\u7684\u9884\u6d4b\u7ed3\u679c\u8d21\u732e\u56fe\u3002Shapley\u503c\u7684\u7edd\u5bf9\u503c\u8d8a\u9ad8\u4ee3\u8868\u8be5\u7279\u5f81\u5bf9\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u7684\u5f71\u54cd\u8d8a\u5927\u3002 \u5173\u952e\u4ee3\u7801\u5757\u5982\u4e0b\uff1a import shap import numpy as np def shapley(model,X): ''' params: model:\u6a21\u578b X:\u8bad\u7ec3\u8be5\u6a21\u578b\u7684\u8bad\u7ec3\u96c6 return:\u6240\u6709\u7279\u5f81\u5bf9\u6240\u6709\u6837\u672c\u7684\u5e73\u5747Shapley\u503c ''' explainer = shap.TreeExplainer(model) shap_values = explainer.shap_values(X) shap.force_plot(explainer.expected_value, shap_values[0,:], X.iloc[0,:]) shap_mean=np.mean(abs(shap_values),axis=0) return shap_mean \u7ed3\u679c\u5982\u4e0b\uff1a \u5168\u5c40\u7ebf\u6027\u66ff\u4ee3\u6a21\u578b \u5168\u5c40\u7ebf\u6027\u66ff\u4ee3\u6a21\u578b\u8fd4\u56de\u5404\u4e2a\u7279\u5f81\u7684\u56de\u5f52\u7cfb\u6570\uff0c\u56de\u5f52\u7cfb\u6570\u7684\u7edd\u5bf9\u503c\u8d8a\u5927\uff0c\u4ee3\u8868\u8be5\u7279\u5f81\u5bf9\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u7684\u5f71\u54cd\u8d8a\u5927\u3002 \u5173\u952e\u4ee3\u7801\u5757\u5982\u4e0b\uff1a from sklearn import Linear_model import numpy as np import pandas as pd def globalsurrogate(testdata,model,X): \"\"\" params: testdata:\u8be5\u6a21\u578b\u7684\u6d4b\u8bd5\u96c6 model\uff1a\u6a21\u578b X\uff1a\u8be5\u6a21\u578b\u7684\u8bad\u7ec3\u96c6 \"\"\" price=model.predict(testdata) coef_list=[] data = getData(userData_pred=price[0], X=X) X_=data.drop(['Final_Price','Label'],axis=1) y=data['Final_Price'] g=linear_model.LinearRegression(fit_intercept=False) g.fit(X_, y) coef_list.append(g.coef_) return coef_list def getData(): \"\"\" \u529f\u80fd\uff1a\u83b7\u53d6\u4e0e\u9884\u6d4b\u7ed3\u679c\u4e00\u6863\u7684\u5bf9\u5e94\u7684\u5b50\u6570\u636e\u96c6 \"\"\" \u7ed3\u679c\u5982\u4e0b\uff1a","title":"\u6a21\u578b\u5206\u6790"},{"location":"analysis/#_1","text":"\u6a21\u578b\u5206\u6790\u6a21\u5757\u7684\u529f\u80fd\uff1a\u5bf9\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u63d0\u4f9b\u53ef\u89e3\u91ca\u3002 \u4ece\u4ee5\u4e0b\u4e24\u4e2a\u89d2\u5ea6\u51fa\u53d1\uff1a Shapley\uff1a\u5c06\u6a21\u578b\u5bf9\u4e8e\u6837\u672c\u7684\u9884\u6d4b\u89e3\u91ca\u4e3a\u6bcf\u4e2a\u7279\u5f81\u5bf9\u9884\u6d4b\u7ed3\u679c\u7684\u8d21\u732e\u503c\u4e4b\u548c\uff0c\u6bcf\u4e2a\u7279\u5f81\u5bf9\u9884\u6d4b\u7ed3\u679c\u7684\u8d21\u732e\u503c\u53ef\u8868\u793a\u4e3a\uff1a $$ f\\left( { X } { j } \\right) =E\\left[ f\\left( z \\right) |z={ X } { i },i=1,2,...,j \\right] $$ \u5168\u5c40\u7ebf\u6027\u66ff\u4ee3\u6a21\u578b\uff1a\u8bad\u7ec3\u7684\u6a21\u578b\u4e3a\u9ed1\u76d2\u6a21\u578b\uff0c\u96be\u4ee5\u76f4\u63a5\u8ba9\u4eba\u7406\u89e3\uff0c\u4f7f\u7528\u7b80\u5355\u7684\u7ebf\u6027\u6a21\u578b\u6765\u903c\u8fd1\u8be5\u6a21\u578b\uff0c\u4ece\u800c\u8ba9\u4eba\u7406\u89e3\u5b83\u7684\u9884\u6d4b\u7ed3\u679c\u3002","title":"\u6a21\u578b\u5206\u6790"},{"location":"analysis/#shapley","text":"Shapley\u6a21\u5757\u8fd4\u56de\u5404\u4e2a\u7279\u5f81\u5bf9\u5404\u4e2a\u6837\u672c\u7684\u5e73\u5747Shapley\u503c\uff0c\u4ee5\u53ca\u5404\u4e2a\u7279\u5f81\u5bf9\u6bcf\u4e00\u4e2a\u6837\u672c\u7684\u9884\u6d4b\u7ed3\u679c\u8d21\u732e\u56fe\u3002Shapley\u503c\u7684\u7edd\u5bf9\u503c\u8d8a\u9ad8\u4ee3\u8868\u8be5\u7279\u5f81\u5bf9\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u7684\u5f71\u54cd\u8d8a\u5927\u3002 \u5173\u952e\u4ee3\u7801\u5757\u5982\u4e0b\uff1a import shap import numpy as np def shapley(model,X): ''' params: model:\u6a21\u578b X:\u8bad\u7ec3\u8be5\u6a21\u578b\u7684\u8bad\u7ec3\u96c6 return:\u6240\u6709\u7279\u5f81\u5bf9\u6240\u6709\u6837\u672c\u7684\u5e73\u5747Shapley\u503c ''' explainer = shap.TreeExplainer(model) shap_values = explainer.shap_values(X) shap.force_plot(explainer.expected_value, shap_values[0,:], X.iloc[0,:]) shap_mean=np.mean(abs(shap_values),axis=0) return shap_mean \u7ed3\u679c\u5982\u4e0b\uff1a","title":"Shapley"},{"location":"analysis/#_2","text":"\u5168\u5c40\u7ebf\u6027\u66ff\u4ee3\u6a21\u578b\u8fd4\u56de\u5404\u4e2a\u7279\u5f81\u7684\u56de\u5f52\u7cfb\u6570\uff0c\u56de\u5f52\u7cfb\u6570\u7684\u7edd\u5bf9\u503c\u8d8a\u5927\uff0c\u4ee3\u8868\u8be5\u7279\u5f81\u5bf9\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u7684\u5f71\u54cd\u8d8a\u5927\u3002 \u5173\u952e\u4ee3\u7801\u5757\u5982\u4e0b\uff1a from sklearn import Linear_model import numpy as np import pandas as pd def globalsurrogate(testdata,model,X): \"\"\" params: testdata:\u8be5\u6a21\u578b\u7684\u6d4b\u8bd5\u96c6 model\uff1a\u6a21\u578b X\uff1a\u8be5\u6a21\u578b\u7684\u8bad\u7ec3\u96c6 \"\"\" price=model.predict(testdata) coef_list=[] data = getData(userData_pred=price[0], X=X) X_=data.drop(['Final_Price','Label'],axis=1) y=data['Final_Price'] g=linear_model.LinearRegression(fit_intercept=False) g.fit(X_, y) coef_list.append(g.coef_) return coef_list def getData(): \"\"\" \u529f\u80fd\uff1a\u83b7\u53d6\u4e0e\u9884\u6d4b\u7ed3\u679c\u4e00\u6863\u7684\u5bf9\u5e94\u7684\u5b50\u6570\u636e\u96c6 \"\"\" \u7ed3\u679c\u5982\u4e0b\uff1a","title":"\u5168\u5c40\u7ebf\u6027\u66ff\u4ee3\u6a21\u578b"},{"location":"train_predict/","text":"\u6a21\u578b\u8bad\u7ec3\u4e0e\u9884\u6d4b \u6a21\u578b\u8bad\u7ec3 \u5728\u6570\u636e\u96c6\u5b8c\u6210\u7279\u5f81\u5de5\u7a0b\uff0c\u5f02\u5e38\u68c0\u6d4b\uff0c\u7279\u5f81\u7f16\u7801\uff0c\u7279\u5f81\u9009\u62e9\u4e4b\u540e\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u3002\u57fa\u4e8e\u4e4b\u524d\u7684\u8c03\u7814\uff0c\u9009\u62e9\u4e86BayesianRidgeRegression\uff0cLassoRegression,GradientBoostingRegression,BaggingRegression,XGBoostRegressor\u4e94\u79cd\u6a21\u578b\u3002 \u5173\u952e\u4ee3\u7801\u5982\u4e0b\uff1a class Model(luigi.Task): def requires(self): return FeatureSelection(is_need=self.is_need, type_of_dataset=self.type_of_dataset, name_of_dataset=self.name_of_dataset, name_of_target=self.name_of_target, type_of_encoding=self.type_of_encoding, cols_num=self.cols_num,num_of_feature=self.num_of_feature) def output(self): return {'model' : luigi.LocalTarget('Model/{0}/{1}/{1}_{2}.pkl'.format(self.type_of_dataset, self.name_of_dataset, self.name_of_model), format=luigi.format.Nop), 'log' : luigi.LocalTarget('Model/{0}/{1}/{1}_{2}_log.txt'.format(self.type_of_dataset, self.name_of_dataset, self.name_of_model)), 'train_X': luigi.LocalTarget('Model/{0}/{1}/{1}_{2}_train_X.csv'.format(self.type_of_dataset, self.name_of_dataset, self.name_of_model))} def run(self): data = pd.read_csv(self.input()['data'].path) model_instance = Model_train(data, self.name_of_target, type_of_dataset=self.type_of_dataset, name_of_dataset=self.name_of_dataset, name_of_model=self.name_of_model) if self.name_of_model == 'bayesianridge': train, test_result, train_X = model_instance.BRreg() elif self.name_of_model == 'lasso': train, test_result, train_X = model_instance.Lreg() elif self.name_of_model =='gradientboosting': train, test_result, train_X = model_instance.GBreg() elif self.name_of_model =='bagging': train, test_result, train_X = model_instance.Breg() elif self.name_of_model =='xgboost': train, test_result, train_X = model_instance.XGBreg() else: pass with self.output()['model'].open('wb') as f: joblib.dump(train, f) with self.output()['log'].open('w') as f: for key, values in test_result.items(): f.write(key + ' ' + str(round(values, 3)) + '\\n') with self.output()['train_X'].open('w') as f: train_X.to_csv(f,index=False) \u8fd0\u884c\u5982\u4e0b\u6307\u4ee4\uff0c\u5b8c\u6210\u6a21\u578b\u8bad\u7ec3 $ python main.py --local-scheduler Model --name-of-model=\"*\" --name-of-dataset=\"&\" \u5176\u4e2d&\u5904\u4e3a\u5df2\u7ecf\u5b8c\u6210\u7f16\u7801\u7684\u6570\u636e\u96c6\u540d\u79f0\uff0c*\u5904\u76ee\u524d\u53ef\u9009\u62e9bayesianridge\uff0classo\uff0cgradientboosting\uff0cbagging\uff0cxgboost\u3002\u5728\u4e0d\u6307\u5b9a\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\uff0c\u9ed8\u8ba4\u6a21\u578b\u8bbe\u7f6e\u4e3axgboost\u3002 \u8bad\u7ec3\u597d\u7684\u6a21\u578b\u4ee5\u53ca\u8bad\u7ec3\u7684\u65e5\u5fd7\u6570\u636e\u4fdd\u5b58\u5728Model\u76ee\u5f55\u4e0b\u3002 \u4f8b\u5982\uff0c\u6570\u636e\u96c6'used_house_data_test'\u5c5e\u4e8eHouse\u7c7b\uff0c\u5c06\u8be5\u6570\u636e\u96c6\u8f7d\u5165\u4e0d\u540c\u7684\u6a21\u578b\u751f\u6210\u7684\u6240\u6709\u6587\u4ef6\u90fd\u4fdd\u5b58\u5728Model/House/used_house_data_test\u76ee\u5f55\u4e0b\u3002 \u8be5\u76ee\u5f55\u4e0b\uff0c\u6709 used_house_data_test_bayesianridge.pkl\u7b49\u4fdd\u5b58\u8bad\u7ec3\u597d\u7684\u6a21\u578b used_house_data_test_bayesianridge_log.txt\u7b49\u8bb0\u5f55\u6a21\u578b\u6307\u6807RMSE,R2,MAE\u3002 \u6a21\u578b\u9884\u6d4b \u5173\u952e\u4ee3\u7801\u5982\u4e0b\uff1a class Prediction(luigi.Task): def requires(self): return Model(is_need=self.is_need, type_of_dataset=self.type_of_dataset, name_of_dataset=self.name_of_dataset, name_of_target=self.name_of_target, type_of_encoding=self.type_of_encoding, name_of_model = self.name_of_model, cols_num = self.cols_num) def output(self): pass def run(self): predictor = joblib.load(self.input()['model'].path) data = pd.read_csv('Dataset/{0}/{1}/{2}.csv'.format(self.type_of_dataset, self.name_of_dataset, name_of_dataset_prediction)) result = predictor.predict(data.drop([self.name_of_target],axis=1)) np.savetxt('./Result/result.csv',result,delimiter=',',fmt='%f') pass \u8fd0\u884c\u6307\u4ee4 python main.py --local-scheduler Prediction --name-of-dataset-prediction=\"\uffe5\" --name-of-target=\"#\" \u5176\u4e2d\uff0c\uffe5\u5904\u4e3a\u65b0\u751f\u6210\u7684csv\u6587\u4ef6\u540d\uff0c#\u5904\u4e3a\u9884\u6d4b\u6807\u7b7e\u540d\uff0c\u4f8b\u5982Final_Price \u9884\u6d4b\u751f\u6210\u7684\u6587\u4ef6result.csv\u4fdd\u5b58\u5728Result\u76ee\u5f55\u3002","title":"\u6a21\u578b\u8bad\u7ec3\u4e0e\u9884\u6d4b"},{"location":"train_predict/#_1","text":"","title":"\u6a21\u578b\u8bad\u7ec3\u4e0e\u9884\u6d4b"},{"location":"train_predict/#_2","text":"\u5728\u6570\u636e\u96c6\u5b8c\u6210\u7279\u5f81\u5de5\u7a0b\uff0c\u5f02\u5e38\u68c0\u6d4b\uff0c\u7279\u5f81\u7f16\u7801\uff0c\u7279\u5f81\u9009\u62e9\u4e4b\u540e\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u3002\u57fa\u4e8e\u4e4b\u524d\u7684\u8c03\u7814\uff0c\u9009\u62e9\u4e86BayesianRidgeRegression\uff0cLassoRegression,GradientBoostingRegression,BaggingRegression,XGBoostRegressor\u4e94\u79cd\u6a21\u578b\u3002 \u5173\u952e\u4ee3\u7801\u5982\u4e0b\uff1a class Model(luigi.Task): def requires(self): return FeatureSelection(is_need=self.is_need, type_of_dataset=self.type_of_dataset, name_of_dataset=self.name_of_dataset, name_of_target=self.name_of_target, type_of_encoding=self.type_of_encoding, cols_num=self.cols_num,num_of_feature=self.num_of_feature) def output(self): return {'model' : luigi.LocalTarget('Model/{0}/{1}/{1}_{2}.pkl'.format(self.type_of_dataset, self.name_of_dataset, self.name_of_model), format=luigi.format.Nop), 'log' : luigi.LocalTarget('Model/{0}/{1}/{1}_{2}_log.txt'.format(self.type_of_dataset, self.name_of_dataset, self.name_of_model)), 'train_X': luigi.LocalTarget('Model/{0}/{1}/{1}_{2}_train_X.csv'.format(self.type_of_dataset, self.name_of_dataset, self.name_of_model))} def run(self): data = pd.read_csv(self.input()['data'].path) model_instance = Model_train(data, self.name_of_target, type_of_dataset=self.type_of_dataset, name_of_dataset=self.name_of_dataset, name_of_model=self.name_of_model) if self.name_of_model == 'bayesianridge': train, test_result, train_X = model_instance.BRreg() elif self.name_of_model == 'lasso': train, test_result, train_X = model_instance.Lreg() elif self.name_of_model =='gradientboosting': train, test_result, train_X = model_instance.GBreg() elif self.name_of_model =='bagging': train, test_result, train_X = model_instance.Breg() elif self.name_of_model =='xgboost': train, test_result, train_X = model_instance.XGBreg() else: pass with self.output()['model'].open('wb') as f: joblib.dump(train, f) with self.output()['log'].open('w') as f: for key, values in test_result.items(): f.write(key + ' ' + str(round(values, 3)) + '\\n') with self.output()['train_X'].open('w') as f: train_X.to_csv(f,index=False) \u8fd0\u884c\u5982\u4e0b\u6307\u4ee4\uff0c\u5b8c\u6210\u6a21\u578b\u8bad\u7ec3 $ python main.py --local-scheduler Model --name-of-model=\"*\" --name-of-dataset=\"&\" \u5176\u4e2d&\u5904\u4e3a\u5df2\u7ecf\u5b8c\u6210\u7f16\u7801\u7684\u6570\u636e\u96c6\u540d\u79f0\uff0c*\u5904\u76ee\u524d\u53ef\u9009\u62e9bayesianridge\uff0classo\uff0cgradientboosting\uff0cbagging\uff0cxgboost\u3002\u5728\u4e0d\u6307\u5b9a\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\uff0c\u9ed8\u8ba4\u6a21\u578b\u8bbe\u7f6e\u4e3axgboost\u3002 \u8bad\u7ec3\u597d\u7684\u6a21\u578b\u4ee5\u53ca\u8bad\u7ec3\u7684\u65e5\u5fd7\u6570\u636e\u4fdd\u5b58\u5728Model\u76ee\u5f55\u4e0b\u3002 \u4f8b\u5982\uff0c\u6570\u636e\u96c6'used_house_data_test'\u5c5e\u4e8eHouse\u7c7b\uff0c\u5c06\u8be5\u6570\u636e\u96c6\u8f7d\u5165\u4e0d\u540c\u7684\u6a21\u578b\u751f\u6210\u7684\u6240\u6709\u6587\u4ef6\u90fd\u4fdd\u5b58\u5728Model/House/used_house_data_test\u76ee\u5f55\u4e0b\u3002 \u8be5\u76ee\u5f55\u4e0b\uff0c\u6709 used_house_data_test_bayesianridge.pkl\u7b49\u4fdd\u5b58\u8bad\u7ec3\u597d\u7684\u6a21\u578b used_house_data_test_bayesianridge_log.txt\u7b49\u8bb0\u5f55\u6a21\u578b\u6307\u6807RMSE,R2,MAE\u3002","title":"\u6a21\u578b\u8bad\u7ec3"},{"location":"train_predict/#_3","text":"\u5173\u952e\u4ee3\u7801\u5982\u4e0b\uff1a class Prediction(luigi.Task): def requires(self): return Model(is_need=self.is_need, type_of_dataset=self.type_of_dataset, name_of_dataset=self.name_of_dataset, name_of_target=self.name_of_target, type_of_encoding=self.type_of_encoding, name_of_model = self.name_of_model, cols_num = self.cols_num) def output(self): pass def run(self): predictor = joblib.load(self.input()['model'].path) data = pd.read_csv('Dataset/{0}/{1}/{2}.csv'.format(self.type_of_dataset, self.name_of_dataset, name_of_dataset_prediction)) result = predictor.predict(data.drop([self.name_of_target],axis=1)) np.savetxt('./Result/result.csv',result,delimiter=',',fmt='%f') pass \u8fd0\u884c\u6307\u4ee4 python main.py --local-scheduler Prediction --name-of-dataset-prediction=\"\uffe5\" --name-of-target=\"#\" \u5176\u4e2d\uff0c\uffe5\u5904\u4e3a\u65b0\u751f\u6210\u7684csv\u6587\u4ef6\u540d\uff0c#\u5904\u4e3a\u9884\u6d4b\u6807\u7b7e\u540d\uff0c\u4f8b\u5982Final_Price \u9884\u6d4b\u751f\u6210\u7684\u6587\u4ef6result.csv\u4fdd\u5b58\u5728Result\u76ee\u5f55\u3002","title":"\u6a21\u578b\u9884\u6d4b"}]}